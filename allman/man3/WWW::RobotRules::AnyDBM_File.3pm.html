<pre><code></code></pre>
<p><br />
</p>
<link rel='stylesheet' href='../style.css'>
<script src='../script.js'></script>
<h1>NAME</h1>
<p>WWW::RobotRules::AnyDBM_File - Persistent RobotRules</p>
<h1>SYNOPSIS</h1>
<p>require WWW::RobotRules::AnyDBM_File; require LWP::RobotUA; # Create
a robot useragent that uses a diskcaching RobotRules my $rules =
WWW::RobotRules::AnyDBM_File-&gt;new( my-robot/1.0, cachefile ); my $ua
= WWW::RobotUA-&gt;new( my-robot/1.0, me@foo.com, $rules ); # Then just
use $ua as usual $res = $ua-&gt;request($req);</p>
<h1>DESCRIPTION</h1>
<p>This is a subclass of <em>WWW::RobotRules</em> that uses the
AnyDBM_File package to implement persistent diskcaching of
<em>robots.txt</em> and host visit information.</p>
<p>The constructor (the <em>new()</em> method) takes an extra argument
specifying the name of the DBM file to use. If the DBM file already
exists, then you can specify undef as agent name as the name can be
obtained from the DBM database.</p>
<h1>SEE ALSO</h1>
<p>WWW::RobotRules, LWP::RobotUA</p>
<h1>AUTHORS</h1>
<p>Hakan Ardo &lt;hakan@munin.ub2.lu.se&gt;, Gisle Aas
&lt;aas@sn.no&gt;</p>
